# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import os
from dotenv import load_dotenv
from strands import Agent, tool
from strands.tools.mcp import MCPClient
from mcp import stdio_client, StdioServerParameters

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# Tavily MCPã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
tavily_mcp = MCPClient(lambda: stdio_client(
    StdioServerParameters(
        command="npx",
        args=["-y", "tavily-mcp@latest"],
        env={"TAVILY_API_KEY": os.getenv("TAVILY_API_KEY")}
    )
))

# ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆæ—¢å­˜çŸ¥è­˜ã§å›ç­”ï¼‰
@tool
def chat_agent(query: str):
    """ä¸€èˆ¬çš„ãªè³ªå•ã«æ—¢å­˜ã®çŸ¥è­˜ã§å›ç­”ã—ã¾ã™"""
    from strands.models.bedrock import BedrockModel
    
    print(f"ğŸ¥ chat_agentå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸ")

    model = BedrockModel(
        # model="us.anthropic.claude-3-7-sonnet-20250219-v1:0",
        model="us.anthropic.claude-3-5-haiku-20241022-v1:0",
        max_tokens=300
    )
    
    agent = Agent(
        model=model,
        system_prompt="ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚"
    )

    print(f"ğŸ¥ chat_agentã‚¯ã‚¨ãƒªå®Ÿè¡Œå‰...")

    return str(agent(query))

# Webæ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆTavily MCPã‚’ä½¿ç”¨ï¼‰
@tool
def web_search_agent(query: str):
    """Webæ¤œç´¢ã‚’ä½¿ã£ã¦æœ€æ–°æƒ…å ±ã‚’èª¿ã¹ã¦å›ç­”ã—ã¾ã™"""
    from strands.models.bedrock import BedrockModel
    
    with tavily_mcp:
        model = BedrockModel(
            model="us.anthropic.claude-3-7-sonnet-20250219-v1:0"
            # max_tokens=400
        )
        
        agent = Agent(
            model=model,
            system_prompt="Webæ¤œç´¢ã§æœ€æ–°æƒ…å ±ã‚’èª¿ã¹ã€ç°¡æ½”ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã®ã¿å«ã‚ã¦ãã ã•ã„ã€‚",
            tools=tavily_mcp.list_tools_sync()
        )
        return str(agent(query))

# Knowledge Baseã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
@tool
def knowledge_base_agent(query: str):
    """Knowledge Baseã‹ã‚‰é–¢é€£æƒ…å ±ã‚’æ¤œç´¢ã—ã¦å›ç­”ã—ã¾ã™"""
    import boto3
    from strands.models.bedrock import BedrockModel
    
    # Bedrock Agent Runtimeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆKnowledge Baseç”¨ï¼‰
    kb_region = os.getenv('KNOWLEDGE_BASE_REGION', 'ap-northeast-1')
    model_region = os.getenv('AWS_REGION', 'us-east-1')
    print(f"ğŸŒ Knowledge Baseãƒªãƒ¼ã‚¸ãƒ§ãƒ³: {kb_region}")
    print(f"ğŸŒ ãƒ¢ãƒ‡ãƒ«ãƒªãƒ¼ã‚¸ãƒ§ãƒ³: {model_region}")
    
    bedrock_agent = boto3.client(
        'bedrock-agent-runtime',
        region_name=kb_region
    )
    
    print('ğŸ“š Knowledge Baseã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå‘¼ã³å‡ºã•ã‚Œã¾ã—ãŸ')

    try:
        print(f"ğŸ” Knowledge Base ID: {os.getenv('KNOWLEDGE_BASE_ID')}")
        print(f"ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}")
        
        MODEL_ARN_RERANK = "arn:aws:bedrock:ap-northeast-1::foundation-model/amazon.rerank-v1:0"

        # Knowledge Baseã‹ã‚‰æ¤œç´¢ï¼ˆãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ + ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰
        try:
            # ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»˜ãã§è©¦è¡Œ
            kb_response = bedrock_agent.retrieve(
                knowledgeBaseId=os.getenv('KNOWLEDGE_BASE_ID'),
                retrievalQuery={'text': query},
                retrievalConfiguration={
                    'vectorSearchConfiguration': {
                        'numberOfResults': 10,
                        'overrideSearchType': 'HYBRID',
                        'rerankingConfiguration': {
                            'bedrockRerankingConfiguration': {
                                'modelConfiguration': {
                                    'modelArn': f'arn:aws:bedrock:{kb_region}::foundation-model/amazon.rerank-v1:0'
                                },
                                'numberOfRerankedResults': 3,
                            },
                            "type": "BEDROCK_RERANKING_MODEL"
                        }
                    }
                }
            )
            print(f"ğŸ”„ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ + Amazon Rerank v1.0 ä½¿ç”¨")
            
        except Exception as rerank_error:
            print(f"âš ï¸  ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {rerank_error}")
            print("ğŸ”„ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®ã¿ã§å†è©¦è¡Œ")
            
            # ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ãªã—ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            kb_response = bedrock_agent.retrieve(
                knowledgeBaseId=os.getenv('KNOWLEDGE_BASE_ID'),
                retrievalQuery={'text': query},
                retrievalConfiguration={
                    'vectorSearchConfiguration': {
                        'numberOfResults': 5,
                        'overrideSearchType': 'HYBRID'
                    }
                }
            )
            print(f"ğŸ”„ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ä½¿ç”¨ï¼ˆãƒ™ã‚¯ã‚¿ãƒ¼ + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰")
        
        print(f"âœ… Knowledge Baseæ¤œç´¢æˆåŠŸ")
        print(f"ğŸ“Š æ¤œç´¢çµæœæ•°: {len(kb_response.get('retrievalResults', []))}")
        
        # æ¤œç´¢çµæœã‚’æ•´ç†
        context = ""
        for i, result in enumerate(kb_response.get('retrievalResults', [])):
            content = result.get('content', {}).get('text', '')
            score = result.get('score', 0)
            print(f"ğŸ“„ çµæœ{i+1} (ã‚¹ã‚³ã‚¢: {score:.3f}): {content[:100]}...")
            context += f"- {content}\n"
        
        if not context:
            print("âš ï¸  Knowledge Baseã«é–¢é€£æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return "Knowledge Baseã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        # print("ğŸ¤– KnoeledgeBaseæ¤œç´¢çµæœå–å¾—å®Œäº†")
        # return f"Knowledge Baseæ¤œç´¢çµæœ:\n{context}"
    
        # æ¤œç´¢çµæœã‚’åŸºã«å›ç­”ç”Ÿæˆ
        print("ğŸ¤– å›ç­”ç”Ÿæˆä¸­...")
        model = BedrockModel(
            # model="us.anthropic.claude-3-5-haiku-20241022-v1:0"
            # model="us.anthropic.claude-3-7-sonnet-20250219-v1:0"
            model="us.anthropic.claude-sonnet-4-20250514-v1:0",

            temperature=0.0,
            max_tokens=1024,
            top_p=0.1,
            top_k=1,
            # Trueã«ã™ã‚‹ã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å‡ºåŠ›ã•ã‚Œã‚‹ã€‚
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ãƒ„ãƒ¼ãƒ«åˆ©ç”¨ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œãªã„ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ãŸã‚ã€OFF
            streaming=False 

        )
        
        agent = Agent(
            model=model,
            system_prompt=f"ä»¥ä¸‹ã®Knowledge Baseã®æƒ…å ±ã‚’åŸºã«ã€è³ªå•ã«ç°¡æ½”ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n{context}"
        )
        
        return str(agent(query))
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"âŒ Knowledge Baseã‚¨ãƒ©ãƒ¼è©³ç´°:")
        print(f"   ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
        print(f"   ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {str(e)}")
        print(f"   ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:\n{error_details}")
        return f"Knowledge Baseæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"

# ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆåˆ¤æ–­ã—ã¦é©åˆ‡ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ç”¨ï¼‰
from strands.models.bedrock import BedrockModel

orchestrator_model = BedrockModel(
    model="us.anthropic.claude-3-5-haiku-20241022-v1:0"
    # model="us.anthropic.claude-3-7-sonnet-20250219-v1:0"
    # model="us.anthropic.claude-sonnet-4-20250514-v1:0"
    # max_tokens=1000
)

orchestrator = Agent(
    model=orchestrator_model,
    system_prompt="""è³ªå•ã‚’åˆ†æã—ã¦é©åˆ‡ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æŒ¯ã‚Šåˆ†ã‘ã¦ãã ã•ã„ã€‚
    
    - é€šå¸¸ã®å›ç­” â†’ chat_agent
    - ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ã£ãŸå›ç­”ï¼ˆã‚¸ãƒ§ã‚¸ãƒ§ã®å¥‡å¦™ãªå†’é™ºã€AWSç³»ã®è³ªå•ï¼‰ â†’ knowledge_base_agent
    
    ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å›ç­”ã‚’ãã®ã¾ã¾è¿”ã—ã¦ãã ã•ã„ã€‚""",
    tools=[chat_agent, knowledge_base_agent]
)

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾—é–¢æ•°
def get_response(question: str):
    """è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã‚’å–å¾—"""
    return str(orchestrator(question))

# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒƒãƒˆ
if __name__ == "__main__":
    print("=== AI ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ ===")
    print("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ'quit'ã§çµ‚äº†ï¼‰")
    print("="*40)
    
    while True:
        try:
            question = input("\nè³ªå•: ")
            
            if question.lower() in ['quit', 'exit', 'çµ‚äº†']:
                print("ãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                break
                
            if not question.strip():
                continue
                
            print("\nå›ç­”ä¸­...")
            result = get_response(question)
            print(f"\nå›ç­”: {result}")
            
        except KeyboardInterrupt:
            print("\n\nãƒãƒ£ãƒƒãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            break
        except Exception as e:
            print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            print("ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")